import asyncio
from playwright.async_api import async_playwright
import pandas as pd
from datetime import datetime
import re
from textblob import TextBlob
from collections import Counter
import json
import aiohttp
from typing import List, Dict, Optional


class AsyncCryptoNewsParser:
    def __init__(self):
        self.sources = {
            "coindesk": {
                "url": "https://www.coindesk.com/",
                "selectors": {
                    "articles": 'div[data-module="ArticleStrip"]',
                    "title": "h3 a",
                    "link": "h3 a",
                    "time": "time",
                },
            },
            "cointelegraph": {
                "url": "https://cointelegraph.com/",
                "selectors": {
                    "articles": ".post-card-inline",
                    "title": ".post-card-inline__title a",
                    "link": ".post-card-inline__title a",
                    "time": ".post-card-inline__date",
                },
            },
            "decrypt": {
                "url": "https://decrypt.co/news",
                "selectors": {
                    "articles": "article",
                    "title": "h2 a, h3 a",
                    "link": "h2 a, h3 a",
                    "time": "time",
                },
            },
            "cryptonews": {
                "url": "https://cryptonews.net/",
                "selectors": {
                    "articles": ".news-item",
                    "title": ".news-title a",
                    "link": ".news-title a",
                    "time": ".news-date",
                },
            },
        }

        self.browser_config = {
            "headless": True,
            "viewport": {"width": 1920, "height": 1080},
            "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        }

    async def create_browser_context(self, playwright):
        """–°–æ–∑–¥–∞–Ω–∏–µ –±—Ä–∞—É–∑–µ—Ä–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        browser = await playwright.chromium.launch(
            headless=self.browser_config["headless"]
        )

        context = await browser.new_context(
            viewport=self.browser_config["viewport"],
            user_agent=self.browser_config["user_agent"],
        )

        return browser, context

    async def parse_source(
        self, source_name: str, source_config: Dict, context
    ) -> List[Dict]:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞"""
        try:
            page = await context.new_page()

            # –ë–ª–æ–∫–∏—Ä—É–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
            await page.route(
                "**/*.{png,jpg,jpeg,gif,svg,css,woff,woff2}",
                lambda route: route.abort(),
            )

            print(f"üîç –ü–∞—Ä—Å–∏–Ω–≥ {source_name}...")
            await page.goto(
                source_config["url"], wait_until="networkidle", timeout=30000
            )

            # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            await page.wait_for_timeout(2000)

            articles = []
            selectors = source_config["selectors"]

            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Å—Ç–∞—Ç—å–∏
            article_elements = await page.query_selector_all(selectors["articles"])

            for element in article_elements[:20]:  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 20 —Å—Ç–∞—Ç–µ–π
                try:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                    title_elem = await element.query_selector(selectors["title"])
                    title = await title_elem.inner_text() if title_elem else "No title"

                    link_elem = await element.query_selector(selectors["link"])
                    link = await link_elem.get_attribute("href") if link_elem else ""

                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ —Å—Å—ã–ª–∫–∏
                    if link and link.startswith("/"):
                        base_url = source_config["url"].rstrip("/")
                        link = base_url + link

                    time_elem = await element.query_selector(selectors["time"])
                    timestamp = (
                        await time_elem.get_attribute("datetime") if time_elem else None
                    )
                    if not timestamp and time_elem:
                        timestamp = await time_elem.inner_text()

                    if title and link:
                        articles.append(
                            {
                                "title": title.strip(),
                                "url": link,
                                "timestamp": timestamp,
                                "source": source_name,
                            }
                        )

                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —ç–ª–µ–º–µ–Ω—Ç–∞ –≤ {source_name}: {e}")
                    continue

            await page.close()
            print(f"‚úÖ {source_name}: —Å–æ–±—Ä–∞–Ω–æ {len(articles)} —Å—Ç–∞—Ç–µ–π")
            return articles

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ {source_name}: {e}")
            return []

    async def get_article_content(self, url: str, context) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å—Ç–∞—Ç—å–∏"""
        try:
            page = await context.new_page()
            await page.route(
                "**/*.{png,jpg,jpeg,gif,svg,css,woff,woff2}",
                lambda route: route.abort(),
            )

            await page.goto(url, wait_until="domcontentloaded", timeout=15000)
            await page.wait_for_timeout(1000)

            # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            content_selectors = [
                "article",
                ".article-content",
                ".post-content",
                ".entry-content",
                '[data-module="ArticleBody"]',
                ".post__content",
                "main p",
            ]

            content = ""
            for selector in content_selectors:
                try:
                    element = await page.query_selector(selector)
                    if element:
                        content = await element.inner_text()
                        if len(content) > 100:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                            break
                except:
                    continue

            await page.close()
            return content[:5000]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä

        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ {url}: {e}")
            return ""

    async def collect_all_news(self) -> List[Dict]:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π —Å–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π —Å–æ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
        async with async_playwright() as playwright:
            browser, context = await self.create_browser_context(playwright)

            try:
                # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
                tasks = []
                for source_name, source_config in self.sources.items():
                    task = self.parse_source(source_name, source_config, context)
                    tasks.append(task)

                # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
                results = await asyncio.gather(*tasks, return_exceptions=True)

                # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                all_articles = []
                for result in results:
                    if isinstance(result, list):
                        all_articles.extend(result)
                    else:
                        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ –∑–∞–¥–∞—á–µ: {result}")

                return all_articles

            finally:
                await context.close()
                await browser.close()

    async def process_articles_batch(
        self, articles: List[Dict], batch_size: int = 10
    ) -> List[Dict]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç–∞—Ç–µ–π –±–∞—Ç—á–∞–º–∏"""
        async with async_playwright() as playwright:
            browser, context = await self.create_browser_context(playwright)

            try:
                processed_data = []
                analyzer = NewsAnalyzer()

                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á–∞–º–∏
                for i in range(0, len(articles), batch_size):
                    batch = articles[i : i + batch_size]
                    print(
                        f"üìÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ {i//batch_size + 1}/{(len(articles)-1)//batch_size + 1}"
                    )

                    # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞
                    content_tasks = []
                    for article in batch:
                        task = self.get_article_content(article["url"], context)
                        content_tasks.append(task)

                    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
                    contents = await asyncio.gather(
                        *content_tasks, return_exceptions=True
                    )

                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—É—é —Å—Ç–∞—Ç—å—é
                    for article, content in zip(batch, contents):
                        if isinstance(content, str):
                            full_text = article["title"] + " " + content

                            analysis = {
                                "title": article["title"],
                                "url": article["url"],
                                "source": article["source"],
                                "timestamp": article.get("timestamp"),
                                "content_length": len(content),
                                "sentiment": analyzer.analyze_sentiment(full_text),
                                "mentioned_cryptos": analyzer.extract_cryptocurrencies(
                                    full_text
                                ),
                                "categories": analyzer.categorize_news(
                                    article["title"], content
                                ),
                                "price_movements": analyzer.extract_price_movements(
                                    content
                                ),
                                "processed_at": datetime.now().isoformat(),
                            }

                            processed_data.append(analysis)

                    # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏
                    await asyncio.sleep(1)

                return processed_data

            finally:
                await context.close()
                await browser.close()


class NewsAnalyzer:
    def __init__(self):
        self.crypto_keywords = {
            "bitcoin": ["bitcoin", "btc"],
            "ethereum": ["ethereum", "eth", "ether"],
            "ripple": ["ripple", "xrp"],
            "cardano": ["cardano", "ada"],
            "solana": ["solana", "sol"],
            "dogecoin": ["dogecoin", "doge"],
            "binance": ["binance", "bnb"],
            "polygon": ["polygon", "matic"],
            "avalanche": ["avalanche", "avax"],
            "chainlink": ["chainlink", "link"],
        }

        self.market_indicators = {
            "bullish": [
                "bull",
                "bullish",
                "pump",
                "moon",
                "surge",
                "rally",
                "breakout",
                "rise",
            ],
            "bearish": [
                "bear",
                "bearish",
                "dump",
                "crash",
                "fall",
                "decline",
                "drop",
                "correction",
            ],
            "neutral": ["stable", "sideways", "consolidation", "range-bound", "flat"],
        }

    def analyze_sentiment(self, text: str) -> str:
        """–£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏"""
        text_lower = text.lower()

        # –ü–æ–¥—Å—á–µ—Ç –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
        bullish_score = sum(
            1 for word in self.market_indicators["bullish"] if word in text_lower
        )
        bearish_score = sum(
            1 for word in self.market_indicators["bearish"] if word in text_lower
        )

        # TextBlob –∞–Ω–∞–ª–∏–∑
        blob = TextBlob(text)
        polarity = blob.sentiment.polarity

        # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        if bullish_score > bearish_score and polarity > -0.1:
            return "bullish"
        elif bearish_score > bullish_score and polarity < 0.1:
            return "bearish"
        else:
            return "neutral"

    def extract_cryptocurrencies(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        text_lower = text.lower()
        found_cryptos = []

        for crypto_name, keywords in self.crypto_keywords.items():
            for keyword in keywords:
                if keyword in text_lower:
                    found_cryptos.append(crypto_name.upper())
                    break

        return list(set(found_cryptos))

    def extract_price_data(self, text: str) -> Dict:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–µ–Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        price_patterns = {
            "prices": r"\$[\d,]+\.?\d*",
            "percentages": r"(\d+\.?\d*)\s*%",
            "market_cap": r"market\s*cap.*?\$[\d,]+\.?\d*[kmb]?",
            "volume": r"volume.*?\$[\d,]+\.?\d*[kmb]?",
        }

        extracted_data = {}
        for key, pattern in price_patterns.items():
            matches = re.findall(pattern, text, re.IGNORECASE)
            extracted_data[key] = matches[:5]  # –ü–µ—Ä–≤—ã–µ 5 —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π

        return extracted_data


class AsyncCryptoNewsAggregator:
    def __init__(self):
        self.parser = AsyncCryptoNewsParser()
        self.analyzer = NewsAnalyzer()

    async def run_full_analysis(self, max_articles: int = 100):
        """–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–µ–π"""
        print("üöÄ –ó–∞–ø—É—Å–∫ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞ –∫—Ä–∏–ø—Ç–æ–Ω–æ–≤–æ—Å—Ç–µ–π...")

        # –°–±–æ—Ä –Ω–æ–≤–æ—Å—Ç–µ–π
        start_time = datetime.now()
        articles = await self.parser.collect_all_news()
        collect_time = datetime.now() - start_time

        print(
            f"üìä –°–æ–±—Ä–∞–Ω–æ {len(articles)} —Å—Ç–∞—Ç–µ–π –∑–∞ {collect_time.total_seconds():.1f} —Å–µ–∫"
        )

        if not articles:
            print("‚ùå –°—Ç–∞—Ç—å–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        articles = articles[:max_articles]

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ –∞–Ω–∞–ª–∏–∑
        start_process = datetime.now()
        processed_data = await self.parser.process_articles_batch(
            articles, batch_size=5
        )
        process_time = datetime.now() - start_process

        print(
            f"‚ö° –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(processed_data)} —Å—Ç–∞—Ç–µ–π –∑–∞ {process_time.total_seconds():.1f} —Å–µ–∫"
        )

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
        report = self.generate_comprehensive_report(processed_data)

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        await self.save_data_async(processed_data, "crypto_news_data.json")
        await self.save_data_async(report, "crypto_news_report.json")

        print("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        self.print_summary(report)

        return processed_data, report

    def generate_comprehensive_report(self, data: List[Dict]) -> Dict:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        df = pd.DataFrame(data)

        return {
            "summary": {
                "total_articles": len(data),
                "processing_time": datetime.now().isoformat(),
                "sources": df["source"].value_counts().to_dict(),
            },
            "sentiment_analysis": {
                "distribution": df["sentiment"].value_counts().to_dict(),
                "by_source": df.groupby("source")["sentiment"].value_counts().to_dict(),
            },
            "cryptocurrency_mentions": {
                "top_mentioned": self.get_top_cryptos(data),
                "by_sentiment": self.get_crypto_sentiment_breakdown(data),
            },
            "categories": df["categories"].explode().value_counts().to_dict(),
            "trends": {
                "most_discussed_topics": self.extract_trending_topics(data),
                "price_movement_frequency": self.analyze_price_movements(data),
            },
        }

    async def save_data_async(self, data, filename: str):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"""
        import aiofiles

        async with aiofiles.open(filename, "w", encoding="utf-8") as f:
            await f.write(json.dumps(data, ensure_ascii=False, indent=2))
        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filename}")

    def print_summary(self, report: Dict):
        """–í—ã–≤–æ–¥ –∫—Ä–∞—Ç–∫–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        print("\nüìà –ö–†–ê–¢–ö–ò–ô –û–¢–ß–ï–¢:")
        print(f"–°—Ç–∞—Ç–µ–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {report['summary']['total_articles']}")
        print(f"–ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {len(report['summary']['sources'])}")
        print(
            f"–¢–æ–ø –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç: {list(report['cryptocurrency_mentions']['top_mentioned'].keys())[:5]}"
        )
        print(f"–ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ä—ã–Ω–∫–∞: {report['sentiment_analysis']['distribution']}")


# –ó–∞–ø—É—Å–∫
async def main():
    aggregator = AsyncCryptoNewsAggregator()
    await aggregator.run_full_analysis(max_articles=50)


if __name__ == "__main__":
    asyncio.run(main())
